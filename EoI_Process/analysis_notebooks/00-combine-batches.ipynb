{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all data from different versions\n",
    "\n",
    "Use this notebook to combine all the previous data coming from different batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the xls file\n",
    "base_dir = \"../EoIs/Inputs/\"\n",
    "versions = [\"Version1_Batches1-6\", \"Version2_Batches7-9\", \"Version3_Batches10-11\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change from xls to csv\n",
    "for version in versions:\n",
    "    for file_name in os.listdir(base_dir + version):\n",
    "        # if filename starts with ~ then it is a temporary file created by excel, skip it\n",
    "        if file_name.startswith(\"~\"):\n",
    "            continue\n",
    "        # then concat the data from the file to the data\n",
    "        if file_name.endswith(\".xlsx\"):\n",
    "            data = pd.read_excel(base_dir + version + \"/\" + file_name)\n",
    "            data.to_csv(base_dir + version + \"/\" + file_name[:-5] + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the data in all csv files in a directory\n",
    "data_v1 = pd.DataFrame()\n",
    "data_v2 = pd.DataFrame()\n",
    "data_v3 = pd.DataFrame()\n",
    "\n",
    "for version in versions:\n",
    "    data = pd.DataFrame()\n",
    "    for file_name in os.listdir(base_dir + version):\n",
    "        # if filename starts with ~ then it is a temporary file created by excel, skip it\n",
    "        if file_name.startswith(\"~\"):\n",
    "            continue\n",
    "        # then concat the data from the file to the data\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            data = pd.concat([data, pd.read_csv(base_dir + version + \"/\" + file_name)], ignore_index=True)\n",
    "    if version == versions[0]:\n",
    "        data_v1 = data\n",
    "    elif version == versions[1]:\n",
    "        data_v2 = data\n",
    "    elif version == versions[2]:\n",
    "        data_v3 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data shape\n",
    "print(data_v1.shape)\n",
    "print(data_v2.shape)\n",
    "print(data_v3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data columns\n",
    "data_v1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Remove columns with sensitive information\n",
    "sensitive_columns = [\"First name\", \"Last name\", \"Email address\", \"IP Address\", \"User Agent\", \"URL\"]\n",
    "data_v1 = data_v1.drop(columns=sensitive_columns)\n",
    "# First version of the data does not have the following columns\n",
    "sensitive_columns = ['Companies House Registration no:', 'Organisation Size', 'Organisation Type', 'Address', 'Postcode', 'Country', \"First name\", \"Last name\", \"Email address\", \"IP Address\", \"User Agent\", \"URL\"]\n",
    "data_v2 = data_v2.drop(columns=sensitive_columns)\n",
    "data_v3 = data_v3.drop(columns=sensitive_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data columns and shape after removing sensitive information\n",
    "data_v1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data_v1 column names to match it with the latest versions\n",
    "data_v1 = data_v1.rename(columns={\n",
    "    \"Position\": \"Job Title\",\n",
    "    \"Agriculture\": \"Agriculture and food processing\",\n",
    "    \"Transportation\": \"Transportation, including logistics and warehousing\",\n",
    "    \"Process deficiencies and storage\": \"Technical infrastructure challenges\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v1.drop(columns=[\n",
    "    'Please add any other information that you would like to provide as part of this Expression of Interest form? (max 200 words)',\n",
    "    'Please tick to confirm Innovate UK Business Connect have your permission to process your data. You can view Innovate UK Business Connect\\'s Privacy Policy here.',\n",
    "    'Please tick to confirm The Alan Turing Institute have your permission to process your data. You can view The Alan Turing Institute\\'s Privacy Policy here.',\n",
    "    'Please tick to confirm Innovate UK KTN have your permission to process your data. You can view Innovate UK KTN\\'s Privacy Policy here.'\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2.drop(columns = [\n",
    "    'Please tick to confirm that you understand as this is a BridgeAI project, the Alan Turing Institute (Privacy Policy) will be sharing your personal data, which is collected on behalf of the BridgeAI programme, with Innovate UK (Privacy Notice), Innovate UK Business Connect (Privacy Policy), BSI Group (Privacy Notice), Hartree Centre (Privacy Notice), and Digital Catapult (Privacy Notice) for the purpose described under the Innovate UK Business Connect privacy notice.',\n",
    "    'Please tick to confirm Innovate UK Business Connect have your permission to process your data. You can view Innovate UK Business Connect\\'s Privacy Policy here.'\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v3.drop(columns=[\n",
    "    'Please tick to confirm that you understand as this is a BridgeAI project, the Alan Turing Institute (Privacy Policy) will be sharing your personal data, which is collected on behalf of the BridgeAI programme, with Innovate UK (Privacy Notice), Innovate UK Business Connect (Privacy Policy), BSI Group (Privacy Notice), Hartree Centre (Privacy Notice), and Digital Catapult (Privacy Notice) for the purpose described under the Innovate UK Business Connect privacy notice.',\n",
    "    'Please tick to confirm Innovate UK Business Connect have your permission to process your data. You can view Innovate UK Business Connect\\'s Privacy Policy here.',\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.concat([data_v1, data_v2, data_v3], axis=0, join='outer', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.fillna(\"N/A\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_csv(\"../EoIs/merged_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the \"Organisation Name\" column has a value more than once, drop duplicates\n",
    "unique_merged_data = merged_data.drop_duplicates(subset=\"Organisation Name\", keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also save this data\n",
    "unique_merged_data.to_csv(\"../EoIs/unique_merged_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
